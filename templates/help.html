<!DOCTYPE html>
<html lang="en">

<head>

    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="description" content="Content-based Image Search">
    <meta name="author" content="jrdelmar">

    <title>How to Use</title>
    <link href="../static/css/fonts-css.css" rel="stylesheet">
    <link href="../static/css/bootstrap.css" rel="stylesheet">
    <link href="../static/css/bootstrap-responsive.css" rel="stylesheet">
    <link href="../static/css/style.css" rel="stylesheet">


<style type="text/css">
/* Overrides of notebook CSS for static HTML export */
body {
  overflow: visible;
  padding: 8px;
}

div#notebook {
  overflow: visible;
  border-top: none;
}@media print {
  div.cell {
    display: block;
    page-break-inside: avoid;
  } 
  div.output_wrapper { 
    display: block;
    page-break-inside: avoid; 
  }
  div.output { 
    display: block;
    page-break-inside: avoid; 
  }
}
</style>
</head>
<body>
  <div tabindex="-1" id="notebook" class="border-box-sizing">
    <div class="container" id="notebook-container">

<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<a href="/" >Back</a>
<!-- HEADER -->
<hr style="border-top: 3px solid #1a082a;margin:0em" />
<div style="width:100%;background-color:#;">
<div style="display:table;width:100%">
    <img src="../static/img/logo.png" style="margin:10px;float:left" /> 
    <span style="text-align:center;display:table-cell;vertical-align:top">
        <h3 style="color:#a03377">Content-Based Image Search</h3>
        <h4 style="color:#a03377">Using Pre-trained Models in Machine Learning as a Digital Forensic Tool</h4>
        <h8 style="color:#e54d86">InceptionV3 | ImageNet | Tensorflow | Keras | Python3</h8>
    </span>
</div></div>
<hr style="border-top: 3px solid #1a082a;margin:0em" />
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<br />


    <! INSTALLATION NOTES START HERE -->
<h1 id="Installation-Notes">Installation Notes<a class="anchor-link" href="#Installation-Notes"></a></h1>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Pre-requisites">Pre-requisites<a class="anchor-link" href="#Pre-requisites"></a></h2><p>The user is expected to know how to install and troubleshoot python-related installations.
A Virtualbox file is provided a semblance of a ready-to-use application. Skip the installation steps if you prefer the Ubuntu Vbox file.</p>
<ul>
<li><a href="https://www.python.org/downloads/">python 3</a></li>
<li><a href="https://www.anaconda.com/distribution/#linux">anaconda</a></li>
<li>source code in <a href="https://github.com/jrdelmar/cbis.git">github</a>:  <code>git clone https://github.com/jrdelmar/cbis.git</code></li>
<li>Ubuntu Virtualbox - The Ubuntu pre-built .ova file can be downloaded from one-drive. The file is too large to be uploaded into github-lfts.
    Download the ova file <a target="_blank" href="http://bit.ly/2HFXnkv"><em>here</em></a> and skip to <a href="/howtouse#Pre-installed-Ubuntu-Virtualbox"><em>this part of the installation</em></a></li>
<li><a href="https://virtualenv.pypa.io/en/latest/">virtual environment</a> - Optional</li>
</ul>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Python-3">Python 3<a class="anchor-link" href="#Python-3"></a></h3><p>This project uses python 3.X, developed under 3.6.X. Install Python 3 in your development by following the official documentation.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Anaconda">Anaconda<a class="anchor-link" href="#Anaconda"></a></h3><p>Anaconda is a package management and deployment environment. Installation via Anaconda is by far the simplest because cartopy, the module used to create offline maps has the simplest installation in the conda environment.</p>
<h4 id="Cartopy"><em>Cartopy</em><a class="anchor-link" href="#Cartopy"></a></h4><p>Pip is another popular option for installing python packages from the python package index. You can also opt to install pip to install dependencies to run the console. However, the <em>cartopy</em> module used for the offline map is a little painful to install outside of the Anaconda environment.
    See some of the issues <a href="https://www.pythonanywhere.com/forums/topic/9366/">here</a> (You had been warned, haha). The recommended installation is through <a href="https://scitools.org.uk/cartopy/docs/v0.15/installing.html">conda</a></p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Virtual-environment---Optional">Virtual environment - Optional<a class="anchor-link" href="#Virtual-environment---Optional"></a></h3><p>virtualenv is a module used by the python community to isolate python environments. This is beneficial for a variety of reasons:</p>
<ul>
<li>allows installation of packages without affecting the global/system site-packages</li>
<li>allows downgrade/upgrade of packages and modules to evaluate the application</li>
</ul>
<p>Completely (hopefully) isolating python environments allows us to create a complete copy of our Python program that works with the dependencies installed.</p>
<p>Reference: <a href="https://virtualenv.pypa.io/en/latest/">https://virtualenv.pypa.io/en/latest/</a></p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<hr>
<p><em>This section discusses a fresh installation from an Ubuntu box in Virtualbox.</em></p>
<h2 id="Install-with-Ubuntu-18.04.1-LTS-Fresh-(VirtualBox)">Install with Ubuntu 18.04.1 LTS Fresh (VirtualBox)<a class="anchor-link" href="#Install-with-Ubuntu-18.04.1-LTS-Fresh-(VirtualBox)"></a></h2><p>Reference: <a href="https://linoxide.com/linux-how-to/setup-python-virtual-environment-ubuntu/">https://linoxide.com/linux-how-to/setup-python-virtual-environment-ubuntu/</a></p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Make sure system is updated
<code>sudo apt-get update</code>
<code>sudo apt-get upgrade</code></p>
<p>Install PIP because Ubuntu is already shipped with Python 3.6
<code>sudo apt-get install python-pip</code>
<code>sudo apt-get install python3-pip</code></p>
<p>Build essentials/developer tools <code>sudo apt-get install build-essential libssl-dev libffi-dev python-dev</code></p>
<p>To solve issues with wheel: <code>sudo -H pip3 install setuptools --upgrade</code></p>
<p>Install the Virtualbox extensions (optional) to allow sharing between host and guest machines such as copy-paste and shared mounted drive. To mount, you can follow this <a href="https://www.smarthomebeginner.com/mount-virtualbox-shared-folder-on-ubuntu-linux/">guide</a>.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Optional"><em>Optional</em><a class="anchor-link" href="#Optional"></a></h3><p>Install virtualenvironment <code>sudo apt-get install -y python3-venv</code></p>
<p>Create virtualenvironment <code>python3 -m venv cbis</code></p>
<p>Activate virtual environment (directory /home/cbis/cbis)</p>

<pre><code>cbis@cbis-Virtualbox:~$ source ~/cbis/bin/activate
(cbis) cbis@cbis-Virtualbox:/venv$ which python3
/home/cbis/cbis/bin/python3
(cbis) cbis@cbis-Virtualbox:~$</code></pre>
<p>To deactivate:
<code>deactivate</code></p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Download-the-Source-code">Download the Source code<a class="anchor-link" href="#Download-the-Source-code"></a></h2><p>Download the source code from github <code>git clone https://github.com/jrdelmar/cbis.git</code></p>

<pre><code>cbis@cbis-VirtualBox:~/app$ git clone https://github.com/jrdelmar/cbis.git
Cloning into 'cbis'...
remote: Enumerating objects: 404, done.
remote: Counting objects: 100% (404/404), done.
remote: Compressing objects: 100% (294/294), done.</code></pre>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Let's install using the Anaconda environment.</p>
<h2 id="Installation-via-Anaconda">Installation via Anaconda<a class="anchor-link" href="#Installation-via-Anaconda"></a></h2><h3 id="Download">Download<a class="anchor-link" href="#Download"></a></h3><p>To install, choose the correct architecture (use Anaconda3 for Python3) and download the anaconda installation from the repository: <a href="https://repo.anaconda.com/archive/">https://repo.anaconda.com/archive/</a></p>

<pre><code>(base) cbis@cbis-VirtualBox:~$ wget https://repo.anaconda.com/archive/Anaconda3-2018.12-Linux-x86_64.sh
--2019-03-18 15:56:52--  https://repo.anaconda.com/archive/Anaconda3-2018.12-Linux-x86_64.sh
Resolving repo.anaconda.com (repo.anaconda.com)... 104.16.131.3, 104.16.130.3, 2606:4700::6810:8203, ...
Connecting to repo.anaconda.com (repo.anaconda.com)|104.16.131.3|:443... connected.
HTTP request sent, awaiting response... 200 OK
Length: 684237703 (653M) [application/x-sh]
Saving to: ‘Anaconda3-2018.12-Linux-x86_64.sh’

Anaconda3-2018.12-Linu 100%[==========================&gt;] 652.54M  2.14MB/s    in 10m 1s

2019-03-18 16:06:54 (1.08 MB/s) - ‘Anaconda3-2018.12-Linux-x86_64.sh’ saved [684237703/684237703]</code></pre>
<h3 id="Verify">Verify<a class="anchor-link" href="#Verify"></a></h3><p>Compare the installation to ensure integrity of the file. Check the md5 hash against the published hash from the repository.</p>

<pre><code>(base) cbis@cbis-VirtualBox:~$ md5sum Anaconda3-2018.12-Linux-x86_64.sh
c9af603d89656bc89680889ef1f92623  Anaconda3-2018.12-Linux-x86_64.sh</code></pre>
<h3 id="Run">Run<a class="anchor-link" href="#Run"></a></h3><p>Run the bash file to proceed with the installation package.</p>

<pre><code>bash Anaconda3-2018.12-Linux-x86_64.sh</code></pre>
<p>The output will be something like this:</p>

<pre><code>Welcome to Anaconda3 2018.12

In order to continue the installation process, please review the license
agreement.
Please, press ENTER to continue
&gt;&gt;&gt;</code></pre>
<p>When the installation completes, add the installation to the PATH file. Type <code>yes</code> so we can use the <code>conda</code> command.</p>

<pre><code>installation finished.
Do you wish the installer to initialize Anaconda3
in your /home/cbis/.bashrc ? [yes|no]
[no] &gt;&gt;&gt;</code></pre>
<h3 id="Activate">Activate<a class="anchor-link" href="#Activate"></a></h3><p>Activate the installation and the virtual environment by running <code>source ~/.bashrc</code>.</p>
<h3 id="Load-Dependencies">Load Dependencies<a class="anchor-link" href="#Load-Dependencies"></a></h3><p>Let's install the dependencies using conda install from the requirements file found in github.
From the terminal, install each dependencies using conda install command.
<code>while read requirement; do conda install --yes $requirement; done &lt; requirements.txt</code></p>
<p>Reference: <a href="https://www.technologyscout.net/2017/11/how-to-install-dependencies-from-a-requirements-txt-file-with-conda/">https://www.technologyscout.net/2017/11/how-to-install-dependencies-from-a-requirements-txt-file-with-conda/</a></p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><em>Now, let's try to check if the installation works.</em></p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Run-the-Code">Run the Code<a class="anchor-link" href="#Run-the-Code"></a></h2><p>Test with running the python code: (no trailing <code>/</code> for the paths)</p>
<p>From the cbis/ directory:</p>
<p><code>python3 predict.py -i dataset/sample -v</code></p>
<p><strong>Predict</strong></p>
<p><code>python3 predict.py -i dataset/sample -v</code></p>

<pre><code>cbis@cbis-VirtualBox:~/app/cbis$ python3 predict.py -i dataset/sample -v
Using TensorFlow backend.
[INFO] Argument List:
--&gt;image_path: dataset/sample
--&gt;model: inception
--&gt;output_folder: None
--&gt;verbose: True
[INFO] Starting to load and index the path dataset/sample ...
[INFO] inception model used.
[INFO] Weight models/inception_v3_weights_tf_dim_ordering_tf_kernels.h5 used
[INFO] Analyzing directory dataset/sample...
[INFO] Number of files found for analysis: 53
[INFO] Model and weights loaded...
[INFO] Classifying image pictures%2Fgun%2Fgun1(1).jpg
1. revolver: 77.64%
2. holster: 8.81%
3. rifle: 4.35%
4. assault_rifle: 2.87%
...
[INFO] Extract exif information for dataset/sample/facebook(1).jpg..
[INFO] File created/saved: output/sample_20190318_171951/predictions_20190318_171951.csv
[INFO] File created/saved: output/sample_20190318_171951/exif_20190318_171951.csv
[INFO] Completed Loading and Indexing of Results
cbis@cbis-VirtualBox:~/app/cbis$</code></pre>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><strong>Search</strong></p>
<p><code>python3 search.py --prediction "output/sample_20190318_171951/predictions_20190318_171951.csv" --exif "output/sample_20190318_171951/exif_20190318_171951.csv" -v</code></p>

<pre><code>cbis@cbis-VirtualBox:~/app/cbis$ python3 search.py --prediction "output/sample_20190318_171951/predictions_20190318_171951.csv" --exif "output/sample_20190318_171951/exif_20190318_171951.csv" -v
[INFO] Argument List:
--&gt;prediction_file: output/sample_20190318_171951/predictions_20190318_171951.csv
--&gt;exif_file: output/sample_20190318_171951/exif_20190318_171951.csv
--&gt;search_list: gun
--&gt;verbose: True
--&gt;top_k: 20
--&gt;threshold: None
[INFO] Starting to load prediction file output/sample_20190318_171951/predictions_20190318_171951.csv and exif file output/sample_20190318_171951/exif_20190318_171951.csv ...
[INFO] Start parsing prediction file output/sample_20190318_171951/predictions_20190318_171951.csv
    dataset/sample/pictures%2Fgun%2Fgun1(1).jpg | revolver | 77.64%
    dataset/sample/pictures%2Fgun%2Fgun3.jpg | revolver | 60.09%
    dataset/sample/gun2.jpg | revolver | 91.55%
    dataset/sample/pictures%2Fgun%2Fgun2(1).jpg | revolver | 91.55%
    dataset/sample/gun1.jpg | revolver | 77.64%
    dataset/sample/gun2(1).jpg | revolver | 91.55%
    dataset/sample/pictures%2Fgun%2Fgun3(1).jpg | revolver | 60.09%
    dataset/sample/gun3.jpg | revolver | 60.09%
    dataset/sample/pictures%2Fgun%2Fgun1.jpg | revolver | 77.64%
    dataset/sample/pictures%2Fgun%2Fgun2.jpg | revolver | 91.55%
[INFO] Total images found: 10
[INFO] Parse exif from output/sample_20190318_171951/exif_20190318_171951.csv..
[INFO] Total exif information: 10
[INFO] Completed Search
cbis@cbis-VirtualBox:~/app/cbis$</code></pre>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><strong>Report</strong></p>
<p><code>python3 report.py --prediction  "output/sample_20190318_171951/predictions_20190318_171951.csv" -v  -k 20 -t 0.50</code></p>

<pre><code>cbis@cbis-VirtualBox:~/app/cbis$ python3 report.py --prediction  "output/sample_20190318_171951/predictions_20190318_171951.csv" -v  -k 20 -t 0.50
[INFO] Argument List:
--&gt;prediction_file: output/sample_20190318_171951/predictions_20190318_171951.csv
--&gt;verbose: True
--&gt;top_k: 20
--&gt;threshold: 0.5
[INFO] Parsing file output/sample_20190318_171951/predictions_20190318_171951.csv for report
[INFO] File created/saved: summary_predictions
[INFO] Total labels:7
[INFO] Completed Report</code></pre>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<hr>
<h1 id="The-Application">The Application<a class="anchor-link" href="#The-Application"></a></h1><p>The source code can be used from the:</p>
<ul>
<li>console (python3)</li>
<li>web browser (via python-flask)</li>
</ul>
<p>The console performs indexing and prediction, search and report.
The web browser performs a more user-friendly parser and a visualisation option.</p>
<p><em>console</em></p>
<ul>
<li>loads the pretrained keras model. For this project, I use the InceptionV3 model that is pre-trained on the ImageNet dataset. </li>
<li>indexes the image directory by performing a prediction per image </li>
<li>stores the prediction for each image in a csv file. The <em>prediction.csv</em> file is stored in the output folder</li>
<li>extracts the exif information for each image and stores that infromation in a csv file. The <em>exif.csv</em> file is stored in the output folder</li>
</ul>
<p><em>web</em></p>
<ul>
<li>parses the prediction and exif files</li>
<li>creates a visual representation of the data</li>
</ul>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<hr>
<h1 id="The-Application-(Console)">The Application (Console)<a class="anchor-link" href="#The-Application-(Console)"></a></h1><p>The application needed for the console is structured this way:</p>

<pre><code>root
 |---cbis/
       |---models/
               |--- contains the model weights pre-trained in imagenet
       |---pyimagesearch/
               |--- contains the classes
       |---output/
               |--- contains the output files
       |---predict.py
       |---search.py
       |---report.py
       |---requirements.txt # pip installation requirements</code></pre>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="1)-Running-the-console-application">1) Running the console application<a class="anchor-link" href="#1)-Running-the-console-application"></a></h2><p><em>This section discusses how to run the python script from the command line</em></p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Step-1.1-Load-and-Predict">Step 1.1 Load and Predict<a class="anchor-link" href="#Step-1.1-Load-and-Predict"></a></h3><p>This module traverses the directory of images, loads the pretrained machine learning model and predicts the top-20 labels as an output. The output is stored as a csv file under the /output directory</p>
<p>predict.py
Parameters:</p>
<ul>
<li><code>-i [Location of Image Path]</code> <em>required, location of images, folder directories will be traversed</em></li>
<li><code>-o [Location of Output Path]</code> _optional, location of prediction and exif files (default: APPLICATION<em>PATH/output/</em></li>
<li><code>-v</code> <em>verbose flag</em></li>
</ul>
<p>Example:
<code>python predict.py --image [IMAGE PATH LOCATION] -v</code></p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Step-1.2-Parse-and-Search">Step 1.2 Parse and Search<a class="anchor-link" href="#Step-1.2-Parse-and-Search"></a></h3><p>After the directory has been indexed, search for guns or objects by parsing the csv files and the exif data. Returns the top-k predictions based on a certain threshold (probability values). Default is search for guns with top-20 predictions and no threshold value (return everything).</p>
<p>search.py
Parameters:</p>
<ul>
<li><code>--prediction [Location of Prediction File Path]</code> <em>location of images, folder directories will be traversed</em></li>
<li><code>--exif [Location of Exif File Path]</code> <em>location of images, folder directories will be traversed</em></li>
<li><code>--search</code> <em>search values, delimited by comma, default is search for guns</em></li>
<li><code>-k</code> <em>top k values, default is 20</em></li>
<li><code>-t</code> <em>threshold value</em></li>
<li><code>-v</code> <em>verbose flag</em></li>
</ul>
<p>Example:</p>
<ul>
<li>search for guns and return top 5 results with probabilities higher than or equal to 85%</li>
</ul>
<p><code>python D:\APP\cbis\search.py --prediction  "output\\predictions.csv" --exif "output\\exif.csv" -v  -k 5 -t 0.85</code></p>
<ul>
<li>search for images with the words: <em>guns, water, and scuba</em> in the predictions and return top 10 results with probabilities higher than or equal to 85%</li>
</ul>
<p><code>python D:\APP\cbis\search.py --prediction  "output\\predictions.csv" --exif "output\\exif.csv" -s "gun,water,scuba" -v -k 10 -t 0.85</code></p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Step-1.3-Report">Step 1.3 Report<a class="anchor-link" href="#Step-1.3-Report"></a></h3><p>Summary of predictions, gives the results in labels and the count of images with that labels</p>
<p>report.py Parameters</p>
<ul>
<li><code>--prediction [Location of Prediction File Path]</code> <em>location of images, folder directories will be traversed</em></li>
<li><code>-k</code> <em>top k values, default is 20</em></li>
<li><code>-t</code> <em>threshold value</em></li>
<li><code>-v</code> <em>verbose flag</em></li>
</ul>
<p>Example: <code>python D:\APP\cbis\report.py --prediction  'D:\\APP\\cbis\\output\\predictions.csv' -v</code></p>
<p>Filename: e.g. summary_predictions_20190226_124946.csv</p>
<table>
<thead><tr>
<th>label</th>
<th>count</th>
</tr>
</thead>
<tbody>
<tr>
<td>lakeside</td>
<td>31</td>
</tr>
<tr>
<td>web_site</td>
<td>28</td>
</tr>
<tr>
<td>altar</td>
<td>23</td>
</tr>
<tr>
<td>palace</td>
<td>23</td>
</tr>
<tr>
<td>assault_rifle</td>
<td>11</td>
</tr>
<tr>
<td>sandbar</td>
<td>9</td>
</tr>
<tr>
<td>vault</td>
<td>9</td>
</tr>
<tr>
<td>revolver</td>
<td>9</td>
</tr>
<tr>
<td>castle</td>
<td>8</td>
</tr>
<tr>
<td>packet</td>
<td>8</td>
</tr>
</tbody>
</table>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<hr>
<h1 id="The-Application-(Web-via-Flask)">The Application (Web via Flask)<a class="anchor-link" href="#The-Application-(Web-via-Flask)"></a></h1><p>The application structure is explained below:</p>

<pre><code>root
 |---cbis/
       |---dataset/
               |--- contains the images for searching
       |---maps/
               |--- contains the maps when the GPS coordinates are found

       |---models/                         -&gt; contains the model weights pre-trained in imagenet
            |---imagenet_class_index.json
            |---inception_v3_weights_tf_dim_ordering_tf_kernels.h5
            |---resnet50_weights_tf_dim_ordering_tf_kernels.h5
            |---vgg16_weights_tf_dim_ordering_tf_kernels.h5
            |---xception_weights_tf_dim_ordering_tf_kernels.h5

       |---pyimagesearch/
            |---loader.py
            |---searcher.py
            |---exif.py
            |---utils.py

        |---static/
               |--- contains the css, javascript image files for rendering the website

        |---templates/
               |--- contains the html files

        |---output/          # contains the output files
               |---predictions.csv         -&gt; contains the output predictions for each image
               |---exif.csv                -&gt; contains the exif data for each processed image
               |---summary_predictions.csv -&gt; contains the predicted labels and the count
               |---unprocessed.csv         -&gt; contains the files that were not processed
        |---app.py                  # flask application
        |---predict.py
        |---search.py
        |---report.py
        |---report.py
        |---requirements.txt   # pip installation requirements</code></pre>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="2)-Running-the-Flask-powered-web-application">2) Running the Flask-powered web application<a class="anchor-link" href="#2)-Running-the-Flask-powered-web-application"></a></h2><p><em>This section discusses how to run the parser and visual tool from the web</em></p>
<p>References:</p>
<ul>
<li><a href="https://www.pyimagesearch.com/2014/12/08/adding-web-interface-image-search-engine-flask/">https://www.pyimagesearch.com/2014/12/08/adding-web-interface-image-search-engine-flask/</a></li>
<li><a href="https://pythonspot.com/flask-web-app-with-python/">https://pythonspot.com/flask-web-app-with-python/</a></li>
<li><a href="https://blog.keras.io/building-a-simple-keras-deep-learning-rest-api.html">https://blog.keras.io/building-a-simple-keras-deep-learning-rest-api.html</a></li>
</ul>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Run the web application using this command from the terminal and from the virtual environment:
<code>source ~/.bashrc</code></p>
<p>Run the application directly from the cbis/ directory
cd</p>

<pre><code>(base) cbis@cbis-VirtualBox:~/$ cd /home/cbis/app/cbis
(base) cbis@cbis-VirtualBox:~/app/cbis$ python3 app.py</code></pre>
<p>To run in debug mode:</p>
<ul>
<li><p>Unix:</p>

<pre><code>export FLASK_DEBUG=1
python3 app.py</code></pre>
</li>
<li><p>Windows:</p>

<pre><code>set FLASK_DEBUG=1
python3 app.py</code></pre>
</li>
</ul>
<p>Output should show the following:</p>

<pre><code>(base) cbis@cbis-VirtualBox:~/app/cbis$ python3 app.py
 * Serving Flask app "app" (lazy loading)
 * Environment: production
   WARNING: Do not use the development server in a production environment.
   Use a production WSGI server instead.
 * Debug mode: on
 * Running on http://0.0.0.0:5000/ (Press CTRL+C to quit)
 * Restarting with stat
 * Debugger is active!
 * Debugger PIN: 119-505-411
127.0.0.1 - - [18/Mar/2019 20:41:26] "GET / HTTP/1.1" 200 -
127.0.0.1 - - [18/Mar/2019 20:41:30] "GET /load HTTP/1.1" 200 -</code></pre>
<p>Open <a href="http://localhost:5000">http://localhost:5000</a> from your favorite web browser.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<hr>
<h1 id="Pre-installed-Ubuntu-Virtualbox">Pre-installed Ubuntu Virtualbox<a class="anchor-link" href="#Pre-installed-Ubuntu-Virtualbox"></a></h1><p><em>This section discusses how to run the ready-to-use version using virtualbox's ova file</em></p>
<p>To skip the installation process, this virtualbox image contains pre-installed dependencies needed to run the application.</p>
<h2 id="Instructions">Instructions<a class="anchor-link" href="#Instructions"></a></h2><ul>
<li>Download the .ova file from the download link (see <a target="_blank" href="/howtouse#Pre-requisites">Pre-requisites</a>) </li>
<li>Import the .ova file (File -&gt; Import Appliance)</li>
<li>Run/Start the Virtual Machine</li>
</ul>
<h3 id="Credentials">Credentials<a class="anchor-link" href="#Credentials"></a></h3><p>cbis/password123</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="The-structure">The structure<a class="anchor-link" href="#The-structure"></a></h2><p>The application needed for the console is structured this way:</p>

<pre><code> /home/cbis/app
             |---cbis/
                   |---dataset/
                   |---maps/

                   |---models/                         -&gt; contains the model weights pre-trained in imagenet
                        |---imagenet_class_index.json
                        |---inception_v3_weights_tf_dim_ordering_tf_kernels.h5
                   |---pyimagesearch/
                           |--- contains python classes

                   |---static/
                          |--- contains the css, javascript image files for rendering the website

                   |---templates/
                          |--- contains the html files

                   |---output/          # contains the output files
                          |---predictions.csv         -&gt; contains the output predictions for each image
                          |---exif.csv                -&gt; contains the exif data for each processed image
                          |---summary_predictions.csv -&gt; contains the predicted labels and the count
                          |---unprocessed.csv         -&gt; contains the files that were not processed
                    |---app.py                  # flask application
                    |---predict.py
                    |---search.py
                    |---report.py
                    |---report.py
                    |---requirements.txt   # pip installation requirements</code></pre>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Update-Git">Update Git<a class="anchor-link" href="#Update-Git"></a></h2><p>Update the git repository in <code>/home/cbis/app/cbis</code> and make sure the code is updated: <code>git pull</code></p>

<pre><code>(base) cbis@cbis-VirtualBox:~/app/cbis$ git pull
Updating c343b06..806f6bc
Fast-forward
 requirements.venv.txt   |  94 ++++++++--
 static/README.txt       |   4 +
 static/js/main.js       |   8 +-
 templates/howtouse.html | 554 ++++++++++++++++++++++++++++++++++++++--------------------
 templates/index.html    |   8 +-
 templates/report.html   |   6 +-
 6 files changed, 457 insertions(+), 217 deletions(-)
 create mode 100644 static/README.txt
(base) (cbis) cbis@cbis-VirtualBox:~/app/cbis$</code></pre>
<h2 id="Run-the-Flask-Web-Application">Run the Flask Web Application<a class="anchor-link" href="#Run-the-Flask-Web-Application"></a></h2><p>Run the flask application: <code>python3 app.py</code> from <code>home/cbis/app/cbis</code></p>

<pre><code>(base) cbis@cbis-VirtualBox:~$ cd ~/app/cbis
(base) cbis@cbis-VirtualBox:~/app/cbis$ python3 app.py
 * Serving Flask app "app" (lazy loading)
 * Environment: production
   WARNING: Do not use the development server in a production environment.
   Use a production WSGI server instead.
 * Debug mode: on
 * Running on http://0.0.0.0:5000/ (Press CTRL+C to quit)
 * Restarting with stat
 * Debugger is active!
 * Debugger PIN: 319-255-407</code></pre>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<hr>
<h2 id="Instructions:">Instructions:<a class="anchor-link" href="#Instructions:"></a></h2><h3 id="Step-1:-Load-and-Index-the-image-directories-from-the-console.">Step 1: Load and Index the image directories from the console.<a class="anchor-link" href="#Step-1:-Load-and-Index-the-image-directories-from-the-console."></a></h3><ul>
<li>The images for prediction should reside in <code>APPLICATION_PATH/cbis/dataset</code></li>
<li>This allows the application to load and identify the top-20 predictions for each and every image in the directory. The filename and path will be displayed. </li>
<li>Run the prediction from the console
<code>python prediction.py --image dataset/FOLDER -v</code></li>
<li>After the prediction completes (depending on the number of files,it might take a while), the file will be saved in the output directory <code>APPLICATION_PATH/cbis/output</code>. </li>
</ul>
<h3 id="Step-2:-Open-the-web-application-and-parse/visualise-results">Step 2: Open the web application and parse/visualise results<a class="anchor-link" href="#Step-2:-Open-the-web-application-and-parse/visualise-results"></a></h3><ul>
<li>Run the flask <code>python app.py</code></li>
<li>From the browser, open: <code>localhost:5000</code></li>
<li>The files are taken from <code>APPLICATION_PATH/cbis/output</code>. Choose any of the files and parse the results. </li>
<li>Start searching! </li>
</ul>

</div>
</div>
</div>
</div>
</div>
<br /><br /><br />
<a href="/" >Back</a>
</body>

 


</html>
